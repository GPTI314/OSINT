# Logstash Pipeline Configuration for OSINT Platform

input {
  # Beats input (for Filebeat, Metricbeat, etc.)
  beats {
    port => 5044
    type => "beats"
  }

  # TCP input for JSON logs
  tcp {
    port => 5000
    codec => json
    type => "json"
  }

  # File input for application logs
  file {
    path => "/app/logs/*.log"
    start_position => "beginning"
    sincedb_path => "/dev/null"
    type => "file"
  }
}

filter {
  # Parse OSINT API logs
  if [fields][service] == "osint-api" or [type] == "osint-api" {
    grok {
      match => {
        "message" => "%{TIMESTAMP_ISO8601:timestamp} %{LOGLEVEL:level} %{GREEDYDATA:log_message}"
      }
    }

    date {
      match => ["timestamp", "yyyy-MM-dd HH:mm:ss", "ISO8601"]
      target => "@timestamp"
    }
  }

  # Parse JSON logs
  if [type] == "json" {
    json {
      source => "message"
    }
  }

  # Add common fields
  mutate {
    add_field => {
      "environment" => "production"
      "platform" => "osint"
    }
  }

  # Remove unnecessary fields
  mutate {
    remove_field => ["agent", "ecs", "input", "host"]
  }

  # Parse error stack traces
  if [level] == "ERROR" or [level] == "CRITICAL" {
    mutate {
      add_tag => ["error"]
    }
  }

  # GeoIP lookup for IP addresses (if present)
  if [client_ip] {
    geoip {
      source => "client_ip"
      target => "geoip"
    }
  }
}

output {
  # Output to Elasticsearch
  elasticsearch {
    hosts => ["elasticsearch:9200"]
    index => "osint-logs-%{+YYYY.MM.dd}"
    document_type => "_doc"
  }

  # Output to stdout for debugging (optional - comment out in production)
  stdout {
    codec => rubydebug
  }
}
